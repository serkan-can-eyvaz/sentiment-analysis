from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import torch
from transformers import BertTokenizer, BertForSequenceClassification
import json
from collections import deque
from typing import List, Dict
import re

app = FastAPI(title="Duygu Analizi Python Servisi")

# CORS ayarlarƒ±nƒ± geni≈ület
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # T√ºm originlere izin ver
    allow_credentials=False,  # Bu False olmalƒ± √ß√ºnk√º allow_origins="*"
    allow_methods=["*"],
    allow_headers=["*"],
)

# Model ve tokenizer'ƒ± y√ºkle
MODEL_PATH = "C:/Users/serka/Desktop/YapayZeka/yorum-analizi-projesi/models/best_model.pt"
TOKENIZER_PATH = "dbmdz/bert-base-turkish-128k-cased"

# Tokenizer'ƒ± y√ºkle
tokenizer = BertTokenizer.from_pretrained(TOKENIZER_PATH)

# Modeli y√ºkle
model = BertForSequenceClassification.from_pretrained(
    TOKENIZER_PATH,
    num_labels=3,
    ignore_mismatched_sizes=True
)
model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))
model.eval()

# Son 5 analizi saklamak i√ßin deque kullan
recent_analyses = deque(maxlen=5)

# Yemek isimleri listesi
FOOD_NAMES = [
    r'h√ºnkar beƒüendi',
    r'mantƒ±',
    r'kebap',
    r'd√∂ner',
    r'lahmacun',
    r'pide',
    r'b√∂rek',
    r'√ßorba',
    r'salata',
    r'pilav'
]

# Duygu analizi √∂zel durumlarƒ±
SENTIMENT_PATTERNS = {
    'olumlu': [
        r'\blezzetli\b',
        r'√ßok g√ºzel',
        r'harika',
        r'm√ºkemmel',
        r's√ºper',
        r'iyi',
        r'ba≈üarƒ±lƒ±',
        r'k√∂t√º deƒüil',
        r'fena deƒüil',
        r'beƒüendim',
        r'tavsiye ederim',
        r'nefis',
        r'≈üahane',
        r'muhte≈üem',
        r'bayƒ±ldƒ±m',
        r'√ßok beƒüendim',
        r'harika olmu≈ü',
        r'√ßok ba≈üarƒ±lƒ±',
        r'√ßok iyi',
        r'√ßok g√ºzel olmu≈ü',
        r'√ßok lezzetli',
        r'√ßok nefis',
        r'√ßok ≈üahane',
        r'√ßok muhte≈üem',
        r'√ßok ba≈üarƒ±lƒ±',
        r'√ßok ba≈üarƒ±lƒ± olmu≈ü',
        r'√ßok g√ºzel olmu≈ü',
        r'√ßok lezzetli olmu≈ü',
        r'√ßok nefis olmu≈ü',
        r'√ßok ≈üahane olmu≈ü',
        r'√ßok muhte≈üem olmu≈ü'
    ],
    'olumsuz': [
        r'lezzetli deƒüil',
        r'k√∂t√º',
        r'berbat',
        r'rezalet',
        r'g√ºzel deƒüil',
        r'iyi deƒüil',
        r'ba≈üarƒ±sƒ±z',
        r'beƒüenmedim',
        r'tavsiye etmem',
        r'√ßok k√∂t√º',
        r'hi√ß beƒüenmedim',
        r'lezzetsiz',
        r'k√∂t√º olmu≈ü',
        r'berbat olmu≈ü',
        r'rezalet olmu≈ü',
        r'g√ºzel deƒüil olmu≈ü',
        r'iyi deƒüil olmu≈ü',
        r'ba≈üarƒ±sƒ±z olmu≈ü',
        r'beƒüenmedim olmu≈ü',
        r'tavsiye etmem olmu≈ü',
        r'√ßok k√∂t√º olmu≈ü',
        r'hi√ß beƒüenmedim olmu≈ü',
        r'lezzetsiz olmu≈ü',
        r'k√∂t√º olmu≈ü',
        r'berbat olmu≈ü',
        r'rezalet olmu≈ü',
        r'g√ºzel deƒüil olmu≈ü',
        r'iyi deƒüil olmu≈ü',
        r'ba≈üarƒ±sƒ±z olmu≈ü',
        r'beƒüenmedim olmu≈ü',
        r'tavsiye etmem olmu≈ü'
    ],
    'n√∂tr': [
        r'orta',
        r'fena',
        r'idare eder',
        r'normal',
        r'eh i≈üte',
        r'ortalama',
        r'ne iyi ne k√∂t√º',
        r'vasat',
        r'standart',
        r'≈ü√∂yle b√∂yle',
        r'idare eder',
        r'normal',
        r'eh i≈üte',
        r'ortalama',
        r'ne iyi ne k√∂t√º',
        r'vasat',
        r'standart',
        r'≈ü√∂yle b√∂yle',
        r'idare eder',
        r'normal',
        r'eh i≈üte',
        r'ortalama',
        r'ne iyi ne k√∂t√º',
        r'vasat',
        r'standart',
        r'≈ü√∂yle b√∂yle'
    ]
}

def preprocess_text(text: str) -> str:
    """Metin √∂n i≈üleme fonksiyonu"""
    text = text.lower()
    text = text.replace('ƒ∞', 'i').replace('I', 'ƒ±')
    text = re.sub(r'[^\w\s]', '', text)
    return text

def is_food_name(text: str) -> bool:
    """Metin i√ßinde yemek ismi olup olmadƒ±ƒüƒ±nƒ± kontrol et"""
    text = preprocess_text(text)
    for food in FOOD_NAMES:
        if re.search(food, text):
            return True
    return False

def check_special_patterns(text: str) -> str:
    text_processed = preprocess_text(text)
    yemek_var = is_food_name(text)
    best_match = None
    best_sentiment = None
    max_length = 0

    for sentiment, patterns in SENTIMENT_PATTERNS.items():
        for pattern in patterns:
            match = re.search(pattern, text_processed)
            if match:
                match_length = len(match.group())
                if match_length > max_length:
                    max_length = match_length
                    best_match = pattern
                    best_sentiment = sentiment

    if yemek_var and best_sentiment:
        return best_sentiment
    if yemek_var:
        return None
    return best_sentiment

def get_sentiment_description(sentiment: str) -> dict:
    """Duygu durumunun a√ßƒ±klamasƒ±nƒ± d√∂nd√ºr"""
    descriptions = {
        'olumlu': {
            'label': 'OLUMLU',
            'description': 'Bu yorum olumlu bir g√∂r√º≈ü bildiriyor',
            'emoji': 'üòä'
        },
        'olumsuz': {
            'label': 'OLUMSUZ',
            'description': 'Bu yorum olumsuz bir g√∂r√º≈ü bildiriyor',
            'emoji': 'üòî'
        },
        'n√∂tr': {
            'label': 'N√ñTR',
            'description': 'Bu yorum ne olumlu ne olumsuz',
            'emoji': 'üòê'
        }
    }
    return descriptions.get(sentiment, {
        'label': 'BELƒ∞RSƒ∞Z',
        'description': 'Yorumun duygu durumu belirlenemedi',
        'emoji': '‚ùì'
    })

def get_sentiment_label(predictions) -> str:
    """Model tahminini T√ºrk√ße sƒ±nƒ±f isimlerine d√∂n√º≈üt√ºr"""
    predicted_class = torch.argmax(predictions).item()
    
    if predicted_class == 0:
        return 'olumsuz'
    elif predicted_class == 1:
        return 'n√∂tr'
    else:
        return 'olumlu'

@app.post("/analyze")
async def analyze_sentiment(request: Request):
    try:
        # Request body'yi oku
        text = await request.body()
        text = text.decode('utf-8')
        print(f"Alƒ±nan metin: {text}")  # Debug log
        
        # √ñnce √∂zel durumlarƒ± kontrol et
        special_sentiment = check_special_patterns(text)
        
        if special_sentiment:
            print(f"√ñzel durum bulundu: {special_sentiment}")  # Debug log
            sentiment_info = get_sentiment_description(special_sentiment)
        else:
            # √ñzel durum bulunamadƒ±ysa modeli kullan
            inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512, padding=True)
            
            with torch.no_grad():
                outputs = model(**inputs)
                predictions = torch.softmax(outputs.logits, dim=1)
                sentiment = get_sentiment_label(predictions[0])
                print(f"Model tahmini: {sentiment}")  # Debug log
                sentiment_info = get_sentiment_description(sentiment)
        
        # Sonucu olu≈ütur
        result = {
            "text": text,
            "sentiment": sentiment_info['label'],
            "description": sentiment_info['description'],
            "emoji": sentiment_info['emoji']
        }
        
        # Son analizi kaydet
        recent_analyses.append(result)
        
        return result
        
    except Exception as e:
        print(f"Hata olu≈ütu: {str(e)}")  # Debug log
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/recent")
async def get_recent_analyses():
    return list(recent_analyses)

@app.get("/health")
async def health_check():
    return {"status": "healthy"} 